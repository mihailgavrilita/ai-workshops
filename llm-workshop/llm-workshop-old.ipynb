{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad6da0bd-0283-40a3-b03e-540f8b6e9cc3",
   "metadata": {},
   "source": [
    "### LLM Workshop -- Data Analysis using Large Language Models\n",
    "Welcome to our LLM Workshop!\n",
    "We hope that today you will learn some practical skills in applying Large Language Models in Data Analysis.\n",
    "Enjoy and don't hesitate to ask questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1ba79-a630-4cb0-a6b2-54d527d4ea9f",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "Before we start, let's make sure that we have everything installed on our machines:\n",
    "\n",
    "- Git;\n",
    "- Pyenv;\n",
    "- Our libraries (dependancies);\n",
    "- Jupiter Lab;\n",
    "- Ollama."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f046bc8f-bb78-4e4d-90cf-a65f44624917",
   "metadata": {},
   "source": [
    "git --version"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8d371ee-b5ff-4bb9-b865-1430706aaff0",
   "metadata": {},
   "source": [
    "curl https://pyenv.run | bash\n",
    "pyenv --version\n",
    "\n",
    "pyenv install 3.11.9\n",
    "pyenv virtualenv 3.11.9 llm-workshop\n",
    "pyenv local llm-workshop"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1f68702-56f8-44ab-bcdf-496f4ebc4095",
   "metadata": {},
   "source": [
    "pip --version\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c28f3aa4-2e7c-4e47-a51e-c53a3bdc664d",
   "metadata": {},
   "source": [
    "pip install jupyterlab\n",
    "jupyter lab"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8cc5d54a-e57a-4065-bfbe-824ebcd1591a",
   "metadata": {},
   "source": [
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "ollama --version\n",
    "\n",
    "ollama pull llama3.2\n",
    "ollama run llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f9dab-42be-49e8-afa4-9ec187493f9d",
   "metadata": {},
   "source": [
    "### Importing Stuff\n",
    "Now that all is installed, we can start by importing any librabies we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6f5061-4890-4c5f-a4fc-f318586449e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain_ollama import OllamaLLM\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa85a35-39ac-4f38-8216-ab6f4ea33e6d",
   "metadata": {},
   "source": [
    "### Connect and Test Model\n",
    "Let's test if we can connect to the model we pulled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba1eba7-090a-427b-8167-f165772792d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "# answer = llm.invoke(\"An LLM Workshop is ...\")\n",
    "# pprint(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e5eb29-db39-483f-95d2-0ea0b35e7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercises:\n",
    "# 1. Download and connect another model (i.e. ollama pull, ollama run)\n",
    "# 2. Connect it connect to compare the results in later exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c648c-6ee1-468a-97eb-ad3aee7a5b99",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "After testing the model, it's time to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb5a7cca-5bc2-4f01-94d7-a8fcb7e03a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"db.json\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "271687f1-1c8b-4950-81d2-d6482f5e7bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercises:\n",
    "# 1. Print the number of job postings in the database\n",
    "# 2. Print any other statistical metrics that would be relevant here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e497e29-bd71-4b0c-a98f-1a5ee2efc6bb",
   "metadata": {},
   "source": [
    "### Categorize Positions\n",
    "With the model working and the data loaded, let's try to categorize some job positions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae8847e-55fc-4cae-8a85-d35c12325f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"Full-Stack Developer\", \"Front-End Developer\", \"Back-End Developer\", \"Dev Ops\", \"Data Engineer\", \"Other\"]\n",
    "prompt = \"\"\"\n",
    "    Please add an appropriate category to the following job descriptions.\n",
    "    Respond with only the list of position descriptions and categories, without additional explanations.\n",
    "    For example: Senior DevOps Engineer - Dev Ops, Full stack web разработчик (django rest framework и react js) - Full-Stack Developer, Senior / lead developer linux, python, c++, engleza - Back-End Developer etc. \n",
    "    Choose from the following categories: {}.\n",
    "    Job Descriptions: {}.\n",
    "\"\"\"\n",
    "category_pattern = r\"(.+) - (.+)\"\n",
    "\n",
    "def categorize_positions(llm, position_descriptions):\n",
    "    llm_response = llm.invoke(prompt.format(', '.join(categories), \", \".join(position_descriptions)))\n",
    "    function_response = []\n",
    "\n",
    "    for line in llm_response.split(\"\\n\"):\n",
    "        match = re.search(category_pattern, line)\n",
    "        if match:\n",
    "            position_description, category = match.groups()\n",
    "            function_response.append((position_description, category))\n",
    "\n",
    "    return function_response\n",
    "\n",
    "# categorize_positions(llm, [\"Lead Python Engineer\", \"Python Developer\", \"Python-разработчик для разработки систем\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2988df1-550b-4afe-a2c3-2e62b57c04f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mishu/.pyenv/versions/3.11.9/envs/llm-workshop/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1..\n",
      "Batch 2..\n",
      "Batch 3..\n",
      "Batch 4..\n",
      "Batch 5..\n",
      "Batch 6..\n",
      "Batch 7..\n",
      "Batch 8..\n",
      "Batch 9..\n"
     ]
    }
   ],
   "source": [
    "category_df = pd.DataFrame({\"Description\": [], 'Category': []})\n",
    "batch_size = 10\n",
    "\n",
    "num_chunks = len(df) // batch_size + (len(df) % batch_size > 0)\n",
    "batches = np.array_split(df[\"position_title\"], num_chunks)\n",
    "\n",
    "for i, batch in enumerate(batches, 1):\n",
    "    print(f\"Batch {i}..\")\n",
    "    new_categories = categorize_positions(llm, batch.tolist())\n",
    "    new_categories_df = pd.DataFrame(new_categories, columns=[\"Description\", \"Category\"])\n",
    "    category_df = pd.concat([category_df, new_categories_df], ignore_index=True)\n",
    "\n",
    "# category_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c36bc8c-6f68-4b9a-bdd9-18e9ded64133",
   "metadata": {},
   "source": [
    "### Vizualize Results\n",
    "Finally we can visualize our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddf18982-9bcf-4d9b-b1c6-1a53429b2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(df, column_name):\n",
    "    counts = df[column_name].value_counts()\n",
    "    counts.plot(kind='bar', color='skyblue', figsize=(10, 6))\n",
    "    plt.xlabel(column_name, fontsize=12)\n",
    "    plt.ylabel(\"Number of Positions\", fontsize=12)\n",
    "    plt.title(f\"Number of Job Positions by {column_name}\", fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# visualize_results(category_df, \"Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6e4c08f-4b99-4540-9d4f-f41d2b623a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercises:\n",
    "# 1. Visualize other data columns available in the database (like position_experience or position_posted)\n",
    "# 2. Visualize any other statistical metrics that can be relevant for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b492a26e-afc6-440b-a4a1-23916dacce3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercises:\n",
    "# 1. How can we handle all extra job categories?\n",
    "# 2. How can we tune the model to be more focused?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5c595-704c-4382-ab29-c8887ac51964",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### References\n",
    "Congratulations for reaching here!\n",
    "For those interested, we've left a couple of references you might find useful in your own projects.\n",
    "Good luck!\n",
    "\n",
    "1. [Pyenv GitHub Repo](https://github.com/pyenv/pyenv);\n",
    "2. [Install Jupyter Lab](https://jupyter.org/install);\n",
    "3. [Download Ollama](https://ollama.com/download);\n",
    "4. [Docs for the OllamaLLM Class](https://python.langchain.com/api_reference/ollama/llms/langchain_ollama.llms.OllamaLLM.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
